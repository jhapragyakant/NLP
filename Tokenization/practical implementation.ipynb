{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc55549d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting click (from nltk)\n",
      "  Using cached click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: joblib in d:\\machine learning\\venv\\lib\\site-packages (from nltk) (1.5.1)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2025.10.23-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: tqdm in d:\\machine learning\\venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in d:\\machine learning\\venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.5/1.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.5/1.5 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.8/1.5 MB 838.9 kB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.8/1.5 MB 838.9 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 824.4 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 860.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 910.0 kB/s eta 0:00:00\n",
      "Downloading regex-2025.10.23-cp310-cp310-win_amd64.whl (277 kB)\n",
      "Using cached click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Installing collected packages: regex, click, nltk\n",
      "\n",
      "   ---------------------------------------- 0/3 [regex]\n",
      "   ---------------------------------------- 0/3 [regex]\n",
      "   ------------- -------------------------- 1/3 [click]\n",
      "   ------------- -------------------------- 1/3 [click]\n",
      "   ------------- -------------------------- 1/3 [click]\n",
      "   ------------- -------------------------- 1/3 [click]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   ---------------------------------------- 3/3 [nltk]\n",
      "\n",
      "Successfully installed click-8.3.0 nltk-3.9.2 regex-2025.10.23\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43001d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize, wordpunct_tokenize, TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ff030e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus= \"\"\"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed tincidunt urna ac enim porta porttitor. Aliquam erat volutpat. Maecenas justo diam, luctus eu pellentesque sit amet, volutpat eget est. Sed finibus dui id dolor porta congue. Pellentesque sit amet ante tempor nulla finibus elementum eleifend at sapien. Aliquam velit massa, facilisis mollis turpis sodales, semper tincidunt erat. Quisque maximus felis vel ex luctus semper. Ut varius odio nec arcu consequat, et maximus ipsum accumsan.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33985d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed tincidunt urna ac enim porta porttitor. Aliquam erat volutpat. Maecenas justo diam, luctus eu pellentesque sit amet, volutpat eget est. Sed finibus dui id dolor porta congue. Pellentesque sit amet ante tempor nulla finibus elementum eleifend at sapien. Aliquam velit massa, facilisis mollis turpis sodales, semper tincidunt erat. Quisque maximus felis vel ex luctus semper. Ut varius odio nec arcu consequat, et maximus ipsum accumsan.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed93fbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "\n",
    "## Paragraph-->sentences \n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73457ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents= sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f36fd666",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\P\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\P\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99915455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem ipsum dolor sit amet, consectetur adipiscing elit.',\n",
       " 'Sed tincidunt urna ac enim porta porttitor.',\n",
       " 'Aliquam erat volutpat.',\n",
       " 'Maecenas justo diam, luctus eu pellentesque sit amet, volutpat eget est.',\n",
       " 'Sed finibus dui id dolor porta congue.',\n",
       " 'Pellentesque sit amet ante tempor nulla finibus elementum eleifend at sapien.',\n",
       " 'Aliquam velit massa, facilisis mollis turpis sodales, semper tincidunt erat.',\n",
       " 'Quisque maximus felis vel ex luctus semper.',\n",
       " 'Ut varius odio nec arcu consequat, et maximus ipsum accumsan.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10200304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2a3c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenization\n",
    "\n",
    "# Paragraph-->words\n",
    "# Sentence--->words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32a7adfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "words= word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7198420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem',\n",
       " 'ipsum',\n",
       " 'dolor',\n",
       " 'sit',\n",
       " 'amet',\n",
       " ',',\n",
       " 'consectetur',\n",
       " 'adipiscing',\n",
       " 'elit',\n",
       " '.',\n",
       " 'Sed',\n",
       " 'tincidunt',\n",
       " 'urna',\n",
       " 'ac',\n",
       " 'enim',\n",
       " 'porta',\n",
       " 'porttitor',\n",
       " '.',\n",
       " 'Aliquam',\n",
       " 'erat',\n",
       " 'volutpat',\n",
       " '.',\n",
       " 'Maecenas',\n",
       " 'justo',\n",
       " 'diam',\n",
       " ',',\n",
       " 'luctus',\n",
       " 'eu',\n",
       " 'pellentesque',\n",
       " 'sit',\n",
       " 'amet',\n",
       " ',',\n",
       " 'volutpat',\n",
       " 'eget',\n",
       " 'est',\n",
       " '.',\n",
       " 'Sed',\n",
       " 'finibus',\n",
       " 'dui',\n",
       " 'id',\n",
       " 'dolor',\n",
       " 'porta',\n",
       " 'congue',\n",
       " '.',\n",
       " 'Pellentesque',\n",
       " 'sit',\n",
       " 'amet',\n",
       " 'ante',\n",
       " 'tempor',\n",
       " 'nulla',\n",
       " 'finibus',\n",
       " 'elementum',\n",
       " 'eleifend',\n",
       " 'at',\n",
       " 'sapien',\n",
       " '.',\n",
       " 'Aliquam',\n",
       " 'velit',\n",
       " 'massa',\n",
       " ',',\n",
       " 'facilisis',\n",
       " 'mollis',\n",
       " 'turpis',\n",
       " 'sodales',\n",
       " ',',\n",
       " 'semper',\n",
       " 'tincidunt',\n",
       " 'erat',\n",
       " '.',\n",
       " 'Quisque',\n",
       " 'maximus',\n",
       " 'felis',\n",
       " 'vel',\n",
       " 'ex',\n",
       " 'luctus',\n",
       " 'semper',\n",
       " '.',\n",
       " 'Ut',\n",
       " 'varius',\n",
       " 'odio',\n",
       " 'nec',\n",
       " 'arcu',\n",
       " 'consequat',\n",
       " ',',\n",
       " 'et',\n",
       " 'maximus',\n",
       " 'ipsum',\n",
       " 'accumsan',\n",
       " '.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "364e2063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit.\n",
      "Sed tincidunt urna ac enim porta porttitor.\n",
      "Aliquam erat volutpat.\n",
      "Maecenas justo diam, luctus eu pellentesque sit amet, volutpat eget est.\n",
      "Sed finibus dui id dolor porta congue.\n",
      "Pellentesque sit amet ante tempor nulla finibus elementum eleifend at sapien.\n",
      "Aliquam velit massa, facilisis mollis turpis sodales, semper tincidunt erat.\n",
      "Quisque maximus felis vel ex luctus semper.\n",
      "Ut varius odio nec arcu consequat, et maximus ipsum accumsan.\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a694a3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem',\n",
       " 'ipsum',\n",
       " 'dolor',\n",
       " 'sit',\n",
       " 'amet',\n",
       " ',',\n",
       " 'consectetur',\n",
       " 'adipiscing',\n",
       " 'elit',\n",
       " '.',\n",
       " 'Sed',\n",
       " 'tincidunt',\n",
       " 'urna',\n",
       " 'ac',\n",
       " 'enim',\n",
       " 'porta',\n",
       " 'porttitor',\n",
       " '.',\n",
       " 'Aliquam',\n",
       " 'erat',\n",
       " 'volutpat',\n",
       " '.',\n",
       " 'Maecenas',\n",
       " 'justo',\n",
       " 'diam',\n",
       " ',',\n",
       " 'luctus',\n",
       " 'eu',\n",
       " 'pellentesque',\n",
       " 'sit',\n",
       " 'amet',\n",
       " ',',\n",
       " 'volutpat',\n",
       " 'eget',\n",
       " 'est',\n",
       " '.',\n",
       " 'Sed',\n",
       " 'finibus',\n",
       " 'dui',\n",
       " 'id',\n",
       " 'dolor',\n",
       " 'porta',\n",
       " 'congue',\n",
       " '.',\n",
       " 'Pellentesque',\n",
       " 'sit',\n",
       " 'amet',\n",
       " 'ante',\n",
       " 'tempor',\n",
       " 'nulla',\n",
       " 'finibus',\n",
       " 'elementum',\n",
       " 'eleifend',\n",
       " 'at',\n",
       " 'sapien',\n",
       " '.',\n",
       " 'Aliquam',\n",
       " 'velit',\n",
       " 'massa',\n",
       " ',',\n",
       " 'facilisis',\n",
       " 'mollis',\n",
       " 'turpis',\n",
       " 'sodales',\n",
       " ',',\n",
       " 'semper',\n",
       " 'tincidunt',\n",
       " 'erat',\n",
       " '.',\n",
       " 'Quisque',\n",
       " 'maximus',\n",
       " 'felis',\n",
       " 'vel',\n",
       " 'ex',\n",
       " 'luctus',\n",
       " 'semper',\n",
       " '.',\n",
       " 'Ut',\n",
       " 'varius',\n",
       " 'odio',\n",
       " 'nec',\n",
       " 'arcu',\n",
       " 'consequat',\n",
       " ',',\n",
       " 'et',\n",
       " 'maximus',\n",
       " 'ipsum',\n",
       " 'accumsan',\n",
       " '.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e972e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem',\n",
       " 'ipsum',\n",
       " 'dolor',\n",
       " 'sit',\n",
       " 'amet',\n",
       " ',',\n",
       " 'consectetur',\n",
       " 'adipiscing',\n",
       " 'elit.',\n",
       " 'Sed',\n",
       " 'tincidunt',\n",
       " 'urna',\n",
       " 'ac',\n",
       " 'enim',\n",
       " 'porta',\n",
       " 'porttitor.',\n",
       " 'Aliquam',\n",
       " 'erat',\n",
       " 'volutpat.',\n",
       " 'Maecenas',\n",
       " 'justo',\n",
       " 'diam',\n",
       " ',',\n",
       " 'luctus',\n",
       " 'eu',\n",
       " 'pellentesque',\n",
       " 'sit',\n",
       " 'amet',\n",
       " ',',\n",
       " 'volutpat',\n",
       " 'eget',\n",
       " 'est.',\n",
       " 'Sed',\n",
       " 'finibus',\n",
       " 'dui',\n",
       " 'id',\n",
       " 'dolor',\n",
       " 'porta',\n",
       " 'congue.',\n",
       " 'Pellentesque',\n",
       " 'sit',\n",
       " 'amet',\n",
       " 'ante',\n",
       " 'tempor',\n",
       " 'nulla',\n",
       " 'finibus',\n",
       " 'elementum',\n",
       " 'eleifend',\n",
       " 'at',\n",
       " 'sapien.',\n",
       " 'Aliquam',\n",
       " 'velit',\n",
       " 'massa',\n",
       " ',',\n",
       " 'facilisis',\n",
       " 'mollis',\n",
       " 'turpis',\n",
       " 'sodales',\n",
       " ',',\n",
       " 'semper',\n",
       " 'tincidunt',\n",
       " 'erat.',\n",
       " 'Quisque',\n",
       " 'maximus',\n",
       " 'felis',\n",
       " 'vel',\n",
       " 'ex',\n",
       " 'luctus',\n",
       " 'semper.',\n",
       " 'Ut',\n",
       " 'varius',\n",
       " 'odio',\n",
       " 'nec',\n",
       " 'arcu',\n",
       " 'consequat',\n",
       " ',',\n",
       " 'et',\n",
       " 'maximus',\n",
       " 'ipsum',\n",
       " 'accumsan',\n",
       " '.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer= TreebankWordTokenizer()\n",
    "tokenizer.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5817e142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For further reading\n",
    "# https://neptune.ai/blog/tokenization-in-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ff6c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
